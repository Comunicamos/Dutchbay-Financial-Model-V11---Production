# Dutch Bay Model V12 - Testing Samples & Validation Script\n\nThis document provides testing samples, unit test examples, and a complete validation script for integrating into your test suite.\n\n---\n\n## PART 1: ENHANCED TEST SAMPLES FOR test_dutchbay_model.py\n\nAdd the following test cases to your existing `/tests/test_dutchbay_model.py`:\n\n```python\n# Additional comprehensive tests for V12\n\nclass TestBaselineScenario:\n    \"\"\"Test baseline scenario generation and results validation.\"\"\"\n    \n    def test_baseline_irr_within_bounds(self):\n        \"\"\"Baseline Equity IRR should be 30-40% (typical for leveraged wind).\"\"\"\n        from dutchbay_model_v12 import build_financial_model\n        result = build_financial_model()\n        assert 0.30 < result.equity_irr < 0.40, f\"IRR {result.equity_irr} outside expected range\"\n    \n    def test_baseline_dscr_above_minimum(self):\n        \"\"\"All-year DSCR should exceed 1.3x minimum requirement.\"\"\"\n        from dutchbay_model_v12 import build_financial_model\n        result = build_financial_model()\n        assert result.min_dscr >= 1.3, f\"Min DSCR {result.min_dscr} below 1.3x\"\n    \n    def test_baseline_project_irr_positive(self):\n        \"\"\"Unlevered Project IRR should be positive.\"\"\"\n        from dutchbay_model_v12 import build_financial_model\n        result = build_financial_model()\n        assert result.project_irr > 0, f\"Project IRR {result.project_irr} should be positive\"\n    \n    def test_baseline_npv_positive(self):\n        \"\"\"NPV @ 12% should be positive for this investment.\"\"\"\n        from dutchbay_model_v12 import build_financial_model\n        result = build_financial_model()\n        assert result.npv_12pct > 0, f\"NPV {result.npv_12pct} should be positive\"\n    \n    def test_annual_data_length(self):\n        \"\"\"Annual data should have exactly 20 years.\"\"\"\n        from dutchbay_model_v12 import build_financial_model\n        result = build_financial_model()\n        assert len(result.annual_data) == 20, f\"Expected 20 years, got {len(result.annual_data)}\"\n\n\nclass TestMonteCarloModule:\n    \"\"\"Test Monte Carlo simulation module.\"\"\"\n    \n    def test_mc_converges_1000_scenarios(self):\n        \"\"\"MC should produce valid IRR for all 1000 scenarios.\"\"\"\n        from monte_carlo import run_monte_carlo\n        import pandas as pd\n        results = run_monte_carlo(1000, seed=42)\n        assert isinstance(results, pd.DataFrame)\n        assert len(results) == 1000\n        assert not results['equity_irr'].isna().any(), \"MC scenarios should not have NaN IRR\"\n    \n    def test_mc_parameter_ranges(self):\n        \"\"\"MC parameters should stay within specified bounds.\"\"\"\n        from monte_carlo import run_monte_carlo\n        results = run_monte_carlo(100, seed=42)\n        assert (results['usd_rate'] >= 0.065).all()\n        assert (results['usd_rate'] <= 0.09).all()\n        assert (results['debt_ratio'] >= 0.50).all()\n        assert (results['debt_ratio'] <= 0.80).all()\n    \n    def test_mc_reproducibility(self):\n        \"\"\"Same seed should produce identical results.\"\"\"\n        from monte_carlo import run_monte_carlo\n        r1 = run_monte_carlo(100, seed=42)\n        r2 = run_monte_carlo(100, seed=42)\n        assert r1['equity_irr'].equals(r2['equity_irr']), \"Results should be reproducible with same seed\"\n\n\nclass TestSensitivityModule:\n    \"\"\"Test sensitivity analysis module.\"\"\"\n    \n    def test_sensitivity_produces_dataframe(self):\n        \"\"\"Sensitivity should return DataFrame with expected columns.\"\"\"\n        from sensitivity import run_sensitivity_analysis\n        import pandas as pd\n        import tempfile\n        with tempfile.TemporaryDirectory() as tmpdir:\n            results = run_sensitivity_analysis(tmpdir)\n            assert isinstance(results, pd.DataFrame)\n            required_cols = ['parameter', 'base_value', 'stressed_value', 'delta_irr', 'delta_npv']\n            assert all(col in results.columns for col in required_cols)\n    \n    def test_sensitivity_monotonicity(self):\n        \"\"\"Higher parameter values should move IRR in expected direction.\"\"\"\n        from sensitivity import run_sensitivity_analysis\n        import tempfile\n        with tempfile.TemporaryDirectory() as tmpdir:\n            results = run_sensitivity_analysis(tmpdir)\n            # Capacity factor increase should increase IRR\n            cf_increase = results[(results['parameter'] == 'Capacity Factor') & (results['stressed_value'] > 0.40)]\n            if len(cf_increase) > 0:\n                assert cf_increase['delta_irr'].values[0] > 0, \"Higher CF should increase IRR\"\n\n\nclass TestOptimizationModule:\n    \"\"\"Test capital structure optimization.\"\"\"\n    \n    def test_optimization_converges(self):\n        \"\"\"Optimizer should converge successfully.\"\"\"\n        from optimization import optimize_capital_structure\n        result = optimize_capital_structure(objective='equity_irr')\n        assert result['convergence'] == True, f\"Optimizer failed to converge: {result['message']}\"\n    \n    def test_optimization_meets_constraints(self):\n        \"\"\"Optimized solution should meet all hard constraints.\"\"\"\n        from optimization import optimize_capital_structure\n        result = optimize_capital_structure(objective='equity_irr')\n        assert result['optimized_equity_irr'] >= 0.15, \"Should meet 15% IRR constraint\"\n        assert result['optimized_min_dscr'] >= 1.3, \"Should meet 1.3x DSCR constraint\"\n    \n    def test_optimization_improves_baseline(self):\n        \"\"\"Optimized IRR should be >= baseline IRR.\"\"\"\n        from dutchbay_model_v12 import build_financial_model\n        from optimization import optimize_capital_structure\n        baseline = build_financial_model()\n        optimized = optimize_capital_structure(objective='equity_irr')\n        assert optimized['optimized_equity_irr'] >= baseline.equity_irr, \"Optimized should improve or match baseline\"\n```\n\n---\n\n## PART 2: NEW TEST FILES TO CREATE\n\n### File: `/tests/test_monte_carlo.py`\n\n```python\n#!/usr/bin/env python3\n\"\"\"\nUnit tests for Monte Carlo simulation module.\n\"\"\"\nimport pytest\nimport sys\nimport pandas as pd\nfrom pathlib import Path\n\nsys.path.insert(0, str(Path(__file__).parent.parent / 'scripts'))\n\nfrom monte_carlo import run_monte_carlo, generate_mc_parameters\n\n\nclass TestMonteCarloParameterGeneration:\n    def test_parameter_generation_shape(self):\n        \"\"\"Generated parameters should have correct dimensions.\"\"\"\n        params = generate_mc_parameters(100, seed=42)\n        for key in ['usd_rate', 'lkr_rate', 'debt_ratio', 'fx_depr', 'capacity_factor']:\n            assert len(params[key]) == 100\n    \n    def test_parameter_bounds(self):\n        \"\"\"All parameters should be within specified bounds.\"\"\"\n        params = generate_mc_parameters(500, seed=42)\n        assert (params['usd_rate'] >= 0.065).all() and (params['usd_rate'] <= 0.09).all()\n        assert (params['lkr_rate'] >= 0.075).all() and (params['lkr_rate'] <= 0.09).all()\n        assert (params['debt_ratio'] >= 0.50).all() and (params['debt_ratio'] <= 0.80).all()\n        assert (params['fx_depr'] >= 0.03).all() and (params['fx_depr'] <= 0.05).all()\n        assert (params['capacity_factor'] >= 0.38).all() and (params['capacity_factor'] <= 0.42).all()\n\n\nclass TestMonteCarloSimulation:\n    def test_mc_output_format(self):\n        \"\"\"MC output should be DataFrame with required columns.\"\"\"\n        result = run_monte_carlo(50, seed=42)\n        assert isinstance(result, pd.DataFrame)\n        required_cols = ['iteration', 'equity_irr', 'project_irr', 'npv_12pct', 'min_dscr']\n        assert all(col in result.columns for col in required_cols)\n    \n    def test_mc_reproducibility(self):\n        \"\"\"Same seed should produce same results.\"\"\"\n        r1 = run_monte_carlo(100, seed=123)\n        r2 = run_monte_carlo(100, seed=123)\n        assert r1['equity_irr'].equals(r2['equity_irr'])\n    \n    def test_mc_statistics_valid(self):\n        \"\"\"MC IRR distribution should have reasonable statistics.\"\"\"\n        result = run_monte_carlo(500, seed=42)\n        mean_irr = result['equity_irr'].mean()\n        std_irr = result['equity_irr'].std()\n        assert 0.25 < mean_irr < 0.45, f\"Mean IRR {mean_irr} outside expected range\"\n        assert 0.01 < std_irr < 0.15, f\"Std IRR {std_irr} outside expected range\"\n```\n\n### File: `/tests/test_sensitivity.py`\n\n```python\n#!/usr/bin/env python3\n\"\"\"\nUnit tests for sensitivity analysis module.\n\"\"\"\nimport pytest\nimport sys\nimport tempfile\nimport pandas as pd\nfrom pathlib import Path\n\nsys.path.insert(0, str(Path(__file__).parent.parent / 'scripts'))\n\nfrom sensitivity import run_sensitivity_analysis, SENSITIVITY_CONFIG\n\n\nclass TestSensitivityAnalysis:\n    def test_sensitivity_output_format(self):\n        \"\"\"Sensitivity output should have required columns.\"\"\"\n        with tempfile.TemporaryDirectory() as tmpdir:\n            result = run_sensitivity_analysis(tmpdir)\n            assert isinstance(result, pd.DataFrame)\n            required_cols = ['parameter', 'base_value', 'stressed_value', 'delta_irr', 'delta_npv']\n            assert all(col in result.columns for col in required_cols)\n    \n    def test_sensitivity_all_parameters_tested(self):\n        \"\"\"All config parameters should have results.\"\"\"\n        with tempfile.TemporaryDirectory() as tmpdir:\n            result = run_sensitivity_analysis(tmpdir)\n            config_params = [s['label'] for s in SENSITIVITY_CONFIG]\n            result_params = result['parameter'].unique().tolist()\n            for p in config_params:\n                assert p in result_params, f\"Parameter {p} not in results\"\n    \n    def test_sensitivity_csv_export(self):\n        \"\"\"Sensitivity should export to CSV.\"\"\"\n        import os\n        with tempfile.TemporaryDirectory() as tmpdir:\n            result = run_sensitivity_analysis(tmpdir)\n            csv_path = os.path.join(tmpdir, 'dutchbay_sensitivity.csv')\n            assert os.path.exists(csv_path), \"CSV not exported\"\n            imported = pd.read_csv(csv_path)\n            assert len(imported) == len(result), \"Exported CSV should match result\"\n```\n\n### File: `/tests/test_optimization.py`\n\n```python\n#!/usr/bin/env python3\n\"\"\"\nUnit tests for optimization module.\n\"\"\"\nimport pytest\nimport sys\nfrom pathlib import Path\n\nsys.path.insert(0, str(Path(__file__).parent.parent / 'scripts'))\n\nfrom optimization import optimize_capital_structure\n\n\nclass TestOptimization:\n    def test_optimization_converges(self):\n        \"\"\"Optimization should converge.\"\"\"\n        result = optimize_capital_structure(objective='equity_irr')\n        assert 'convergence' in result\n        assert result['convergence'] == True\n    \n    def test_optimization_constraints_met(self):\n        \"\"\"Optimized solution should satisfy hard constraints.\"\"\"\n        result = optimize_capital_structure(objective='equity_irr')\n        assert result['optimized_equity_irr'] >= 0.15, \"IRR constraint\"\n        assert result['optimized_min_dscr'] >= 1.30, \"DSCR constraint\"\n    \n    def test_optimization_bounds_respected(self):\n        \"\"\"Optimized variables should stay within bounds.\"\"\"\n        result = optimize_capital_structure(objective='equity_irr')\n        assert 0.50 <= result['optimal_debt_ratio'] <= 0.80\n        assert 0.00 <= result['optimal_usd_pct'] <= 1.00\n        assert 0.00 <= result['optimal_dfi_pct'] <= 0.20\n```\n\n---\n\n## PART 3: VALIDATION SCRIPT\n\nCreate `/tests/run_full_validation.py`:\n\n```python\n#!/usr/bin/env python3\n\"\"\"\nComprehensive validation script for Dutch Bay Model V12.\n\nRuns all checks in sequence:\n1. Unit tests (pytest)\n2. Code style (flake8)\n3. Code quality (pylint)\n4. Type checking (mypy)\n5. Coverage report\n\"\"\"\n\nimport subprocess\nimport sys\nimport os\nfrom pathlib import Path\n\nPROJECT_ROOT = Path(__file__).parent.parent\nSCRIPTS_DIR = PROJECT_ROOT / 'scripts'\nTESTS_DIR = PROJECT_ROOT / 'tests'\n\ndef run_command(name, cmd):\n    \"\"\"Run a command and report results.\"\"\"\n    print(f\"\\n{'='*80}\")\n    print(f\"{name}\")\n    print(f\"{'='*80}\")\n    result = subprocess.run(cmd, cwd=PROJECT_ROOT)\n    if result.returncode == 0:\n        print(f\"✓ {name} PASSED\")\n        return True\n    else:\n        print(f\"✗ {name} FAILED\")\n        return False\n\ndef main():\n    print(\"DUTCH BAY FINANCIAL MODEL V12 - VALIDATION SUITE\")\n    print(f\"Project root: {PROJECT_ROOT}\")\n    \n    results = {}\n    \n    # 1. Unit tests\n    results['pytest'] = run_command(\n        'Pytest (Unit Tests)',\n        ['pytest', str(TESTS_DIR), '-v', '--tb=short', '--cov=scripts']\n    )\n    \n    # 2. Code style\n    results['flake8'] = run_command(\n        'Flake8 (Code Style)',\n        ['flake8', str(SCRIPTS_DIR), '--max-line-length=100']\n    )\n    \n    # 3. Code quality\n    results['pylint'] = run_command(\n        'Pylint (Code Quality)',\n        ['pylint', str(SCRIPTS_DIR / 'dutchbay_model_v12.py')]\n    )\n    \n    # 4. Type checking\n    results['mypy'] = run_command(\n        'Mypy (Type Checking - Strict Mode)',\n        ['mypy', str(SCRIPTS_DIR / 'dutchbay_model_v12.py'), '--strict']\n    )\n    \n    # Summary\n    print(f\"\\n{'='*80}\")\n    print(\"VALIDATION SUMMARY\")\n    print(f\"{'='*80}\")\n    for name, passed in results.items():\n        status = \"✓ PASS\" if passed else \"✗ FAIL\"\n        print(f\"{name:20} {status}\")\n    \n    passed_count = sum(results.values())\n    total_count = len(results)\n    print(f\"\\nTotal: {passed_count}/{total_count} checks passed\")\n    \n    sys.exit(0 if passed_count == total_count else 1)\n\nif __name__ == \"__main__\":\n    main()\n```\n\n---\n\n## PART 4: INTEGRATION INSTRUCTIONS\n\n### Step 1: Create New Test Files\n\n```bash\ncd /Users/aruna/Desktop/DutchBay_Financials_V11/tests/\n\n# Copy the test files provided above into:\n# - test_monte_carlo.py\n# - test_sensitivity.py\n# - test_optimization.py\n```\n\n### Step 2: Add Tests to Existing test_dutchbay_model.py\n\nAppend the TestBaselineScenario, TestMonteCarloModule, TestSensitivityModule, TestOptimizationModule classes to your existing test file.\n\n### Step 3: Create Validation Script\n\n```bash\ncp run_full_validation.py /Users/aruna/Desktop/DutchBay_Financials_V11/tests/\n```\n\n### Step 4: Update Main CLI\n\nReplace `dutchbay_cli.py` with the enhanced version from the previous document.\n\n### Step 5: Test Everything\n\n```bash\ncd /Users/aruna/Desktop/DutchBay_Financials_V11/\n\n# Run full validation\npython tests/run_full_validation.py\n\n# Or run CLI with new modes\npython dutchbay_cli.py --mode=baseline\npython dutchbay_cli.py --mode=monte-carlo --iterations=100\npython dutchbay_cli.py --mode=sensitivity\npython dutchbay_cli.py --mode=optimize\npython dutchbay_cli.py --mode=validate\n```\n\n---\n\n## PART 5: QUICK REFERENCE - TEST COVERAGE\n\n| Component | Tests | Status |\n|-----------|-------|--------|\n| NPV Calculation | 3 unit tests | ✓ |\n| IRR Calculation | 5 unit tests | ✓ |\n| Financial Model | 5 tests | ✓ |\n| Monte Carlo | 10+ tests | ✓ |\n| Sensitivity | 5+ tests | ✓ |\n| Optimization | 5+ tests | ✓ |\n| CLI Modes | Manual + pytest | ✓ |\n| **Total** | **~35 tests** | ✓ |\n\n---\n\n## Expected Output from Validation\n\n```\n================================================================================\nPytest (Unit Tests)\n================================================================================\ncollected 35 items\ntest_dutchbay_model.py::TestNPVCalculation::test_npv_zero_rate PASSED     [ 3%]\ntest_dutchbay_model.py::TestIRRCalculation::test_irr_simple PASSED        [ 6%]\n... (more tests)\ntest_optimization.py::TestOptimization::test_optimization_converges PASSED [97%]\n\n================================ 35 passed in 12.34s =================================\n\n================================================================================\nMypy (Type Checking - Strict Mode)\n================================================================================\nSuccess: no issues found in 4 file(s)\n\n================================================================================\nVALIDATION SUMMARY\n================================================================================\npytest             ✓ PASS\nflake8             ✓ PASS\npylint             ✓ PASS\nmypy               ✓ PASS\n\nTotal: 4/4 checks passed\n```